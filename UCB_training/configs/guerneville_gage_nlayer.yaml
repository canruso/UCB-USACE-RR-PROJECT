# --- Experiment configurations --------------------------------------------------------------------

# experiment name, used as folder name
experiment_name: testing_run

# files to specify training, validation and test basins (relative to code root or absolute path)
train_basin_file: guerneville
validation_basin_file: guerneville
test_basin_file: guerneville

# training, validation and test time periods (format = 'dd/mm/yyyy')
train_start_date: "01/10/2000"
train_end_date: "30/09/2002" 
validation_start_date: "01/10/2002"
validation_end_date: "30/09/2004"
test_start_date: "01/10/2004"
test_end_date: "29/09/2009"


# which GPU (id) to use [in format of cuda:0, cuda:1 etc, or cpu or None]
device: cuda:0

physics_informed: false
physics_data_file: null

# --- Validation configuration ---------------------------------------------------------------------

# specify after how many epochs to perform validation
validate_every: 5

# specify how many random basins to use for validation
validate_n_random_basins: 1

# specify which metrics to calculate during validation (see neuralhydrology.evaluation.metrics)
# this can either be a list or a dictionary. If a dictionary is used, the inner keys must match the name of the
# target_variable specified below. Using dicts allows for different metrics per target variable.
metrics:
  - NSE
  - MSE

# --- Model configuration --------------------------------------------------------------------------

# base model type [lstm, ealstm, cudalstm, embcudalstm, mtslstm]
# (has to match the if statement in modelzoo/__init__.py)
model: cudalstm

# prediction head [regression]. Define the head specific parameters below
head: regression

# ----> Regression settings <----
output_activation: linear

# ----> General settings <----

# Number of cell states of the LSTM
hidden_size: 64

# Initial bias value of the forget gate
initial_forget_bias: 3

# Dropout applied to the output of the LSTM
output_dropout: 0.5

#number of LSTM layers
num_layers: 1
dev_mode: True

# --- Training configuration -----------------------------------------------------------------------

# specify optimizer [Adam]
optimizer: Adam

# specify loss [MSE, NSE, RMSE]
loss: NSE

# specify learning rates to use starting at specific epochs (0 is the initial learning rate)
learning_rate:
  0: 1e-2
  20: 5e-3
  30: 1e-3

# Mini-batch size
batch_size: 256

# Number of training epochs
epochs: 32

# If a value, clips the gradients during training to that norm.
clip_gradient_norm: 1

# Defines which time steps are used to calculate the loss. Can't be larger than seq_length.
# If use_frequencies is used, this needs to be a dict mapping each frequency to a predict_last_n-value, else an int.
predict_last_n: 1

# Length of the input sequence
# If use_frequencies is used, this needs to be a dict mapping each frequency to a seq_length, else an int.
seq_length: 365

# Number of parallel workers used in the data pipeline
# num_workers: 8

# Log the training loss every n steps
log_interval: 16

# If true, writes logging results into tensorboard file
log_tensorboard: True

# If a value and greater than 0, logs n random basins as figures during validation
log_n_figures: 1

# Save model weights every n epochs
save_weights_every: 16


# --- Early Stopping Configuration ------------------------------------------------------------
# Enable early stopping based on validation performance
early_stopping: False

# Early stopping mode: "patience", "slope", or "none"
# - "patience": Traditional approach (stops after N validations without improvement)
# - "slope": Trend-based approach (stops when loss trend shows no improvement)
# - "none": Disables early stopping
early_stopping_mode: "patience"

# --- Patience Mode Settings ---
# Number of validation epochs with no improvement before stopping training
# With validate_every=5, patience=3 means stopping after 15 epochs of no improvement
patience_early_stopping: 3

# Minimum change to qualify as improvement (default: 0.0)
min_delta_early_stopping: 0.0

# Minimum number of epochs before early stopping can trigger
minimum_epochs_before_early_stopping: 10

# --- Slope Mode Settings (only used if early_stopping_mode: "slope") ---
# Number of epochs in rolling window for trend analysis
early_stopping_slope_window: 7

# Consecutive non-improving trend checks before stopping
early_stopping_slope_patience: 2

# Minimum epoch before slope checks begin
early_stopping_slope_min_epoch: 8

# EMA smoothing factor in (0,1]; higher = more reactive
early_stopping_slope_ema_alpha: 0.4

# Apply log transform to smoothed loss (makes thresholds represent % changes)
early_stopping_slope_use_log: True

# Epsilon added before log if loss <= 0
early_stopping_slope_log_eps: 1.0e-12

# Per-epoch improvement threshold in log space (~% change/epoch; 1e-3 ≈ 0.1%)
early_stopping_slope_eps_slope: 1.0e-3

# Required total improvement across window in log space (~%; 0.01 ≈ 1%)
early_stopping_slope_min_window_gain: 0.01

# Check window stability before acting
early_stopping_slope_variance_guard: True

# Max coefficient of variation to consider stable (~%; 0.01 ≈ 1%)
early_stopping_slope_variance_cv_max: 0.01

# --- Data configurations --------------------------------------------------------------------------

# which data set to use [camels_us, camels_gb, global, hourly_camels_us]
dataset: russian_river

# Path to data set root
data_dir: "F:/Dino/UCB-USACE-LSTMs/data/11082024_data_streamflow_met_Russian_River_share_UCB"

# Forcing product [daymet, maurer, maurer_extended, nldas, nldas_extended, nldas_hourly]
# can be either a list of forcings or a single forcing product
# forcings:
#   - maurer
#   - daymet
#   - nldas

dynamic_inputs:
  #Subbasins (precip & ET)
  - BIG SULPHUR CR ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - DRY CREEK 10 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - EF RUSSIAN 20 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - GREEN VALLEY ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - LAGUNA ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 20 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 30 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 40 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 50 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 60 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - RUSSIAN 70 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - SANTA ROSA CR 10 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - SANTA ROSA CR 20 ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - WF RUSSIAN ET-POTENTIAL RUN:BASIN AVERAGE 60 YR
  - BIG SULPHUR CR PRECIP-INC SCREENED
  - DRY CREEK 10 PRECIP-INC SCREENED
  - EF RUSSIAN 20 PRECIP-INC SCREENED
  - GREEN VALLEY PRECIP-INC SCREENED
  - LAGUNA PRECIP-INC SCREENED
  - RUSSIAN 20 PRECIP-INC SCREENED
  - RUSSIAN 30 PRECIP-INC SCREENED
  - RUSSIAN 40 PRECIP-INC SCREENED
  - RUSSIAN 50 PRECIP-INC SCREENED
  - RUSSIAN 60 PRECIP-INC SCREENED
  - RUSSIAN 70 PRECIP-INC SCREENED
  - SANTA ROSA CR 10 PRECIP-INC SCREENED
  - SANTA ROSA CR 20 PRECIP-INC SCREENED
  - WF RUSSIAN PRECIP-INC SCREENED
  #met gages: UKIAH and SANTA ROSA
  - UKIAH CA HUMIDITY USAF-NOAA
  - UKIAH CA SOLAR RADIATION USAF-NOAA
  - UKIAH CA TEMPERATURE USAF-NOAA
  - UKIAH CA WINDSPEED USAF-NOAA
  - SANTA ROSA CA HUMIDITY USAF-NOAA
  - SANTA ROSA CA SOLAR RADIATION USAF-NOAA
  - SANTA ROSA CA TEMPERATURE USAF-NOAA
  - SANTA ROSA CA WINDSPEED USAF-NOAA
  #Boundary Conditions (inflows)
  - UKIAH CA FLOW USGS-MERGED
  - GEYSERVILLE CA FLOW USGS-MERGED
  
# which columns to use as target
target_variables:
  - NR GUERNEVILLE FLOW COE GRN

# clip negative predictions to zero for all variables listed below. Should be a list, even for single variables.
clip_targets_to_zero:
#   - QObs(mm/d)
  - NR GUERNEVILLE FLOW COE GRN
